{
  
    
        "post0": {
            "title": "Covid_19 Data Visualization & Analysis",
            "content": "Project Submitted to Stanford Code in Place May 2021 by Srividhya Ammanur . Data Source: https://github.com/CSSEGISandData/COVID-19 . This is the data repository for the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). Also, Supported by ESRI Living Atlas Team and the Johns Hopkins University Applied Physics Lab (JHU APL). . Install Libraries . import plotly.express as px import plotly.graph_objects as go import plotly.figure_factory as ff from plotly.subplots import make_subplots import plotly.offline as pyo from plotly import tools import plotly plotly.offline.init_notebook_mode(connected=True) import plotly.io as pio pio.renderers.default = &#39;colab&#39; import folium import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns color = sns.color_palette() %matplotlib inline import math import random from datetime import timedelta import warnings warnings.filterwarnings(&#39;ignore&#39;) # color palette cnf = &#39;#393e46&#39; dth = &#39;#ff2e63&#39; rec = &#39;#21bf73&#39; act = &#39;#fe9801&#39; . Load the data . !git clone https://github.com/laxmimerit/Covid-19-Preprocessed-Dataset.git . Cloning into &#39;Covid-19-Preprocessed-Dataset&#39;... remote: Enumerating objects: 4406, done. remote: Counting objects: 100% (717/717), done. remote: Compressing objects: 100% (389/389), done. remote: Total 4406 (delta 331), reused 714 (delta 328), pack-reused 3689 Receiving objects: 100% (4406/4406), 260.43 MiB | 24.12 MiB/s, done. Resolving deltas: 100% (2454/2454), done. Checking out files: 100% (893/893), done. . import os . try: os.system(&quot;rm -rf Covid-19-Preprocessed-Dataset&quot;) except: print(&#39;File does not exist&#39;) . !git clone https://github.com/laxmimerit/Covid-19-Preprocessed-Dataset.git . Cloning into &#39;Covid-19-Preprocessed-Dataset&#39;... remote: Enumerating objects: 4406, done. remote: Counting objects: 100% (717/717), done. remote: Compressing objects: 100% (389/389), done. remote: Total 4406 (delta 331), reused 714 (delta 328), pack-reused 3689 Receiving objects: 100% (4406/4406), 260.43 MiB | 24.19 MiB/s, done. Resolving deltas: 100% (2454/2454), done. Checking out files: 100% (893/893), done. . df = pd.read_csv(&#39;Covid-19-Preprocessed-Dataset/preprocessed/covid_19_data_cleaned.csv&#39;, parse_dates=[&#39;Date&#39;]) country_daywise = pd.read_csv(&#39;Covid-19-Preprocessed-Dataset/preprocessed/country_daywise.csv&#39;, parse_dates=[&#39;Date&#39;]) countrywise = pd.read_csv(&#39;Covid-19-Preprocessed-Dataset/preprocessed/countrywise.csv&#39;) daywise = pd.read_csv(&#39;Covid-19-Preprocessed-Dataset/preprocessed/daywise.csv&#39;, parse_dates=[&#39;Date&#39;]) . df.head(5) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 0 2020-01-22 | NaN | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 1 2020-01-23 | NaN | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 2 2020-01-24 | NaN | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 3 2020-01-25 | NaN | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 4 2020-01-26 | NaN | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . Summary Statistics . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 140718 entries, 0 to 140717 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 Date 140718 non-null datetime64[ns] 1 Province/State 43912 non-null object 2 Country 140718 non-null object 3 Lat 140718 non-null float64 4 Long 140718 non-null float64 5 Confirmed 140718 non-null int64 6 Recovered 140718 non-null int64 7 Deaths 140718 non-null int64 8 Active 140718 non-null int64 dtypes: datetime64[ns](1), float64(2), int64(4), object(2) memory usage: 9.7+ MB . df.describe() . Lat Long Confirmed Recovered Deaths Active . count 140718.000000 | 140718.000000 | 1.407180e+05 | 1.407180e+05 | 140718.000000 | 1.407180e+05 | . mean 20.346814 | 22.838207 | 1.926373e+05 | 1.136244e+05 | 4563.426214 | 7.444941e+04 | . std 25.153049 | 74.267991 | 1.321967e+06 | 7.212731e+05 | 26487.639690 | 1.018568e+06 | . min -51.796300 | -178.116500 | 0.000000e+00 | 0.000000e+00 | 0.000000 | -1.342878e+06 | . 25% 4.535300 | -19.020800 | 6.700000e+01 | 7.000000e+00 | 0.000000 | 3.000000e+00 | . 50% 21.607879 | 20.972650 | 1.282000e+03 | 6.850000e+02 | 19.000000 | 1.960000e+02 | . 75% 40.463667 | 85.240100 | 2.727100e+04 | 1.331675e+04 | 472.000000 | 5.096000e+03 | . max 71.706900 | 178.065000 | 3.332644e+07 | 2.659766e+07 | 596434.000000 | 3.273000e+07 | . df.dtypes . Date datetime64[ns] Province/State object Country object Lat float64 Long float64 Confirmed int64 Recovered int64 Deaths int64 Active int64 dtype: object . df.shape . (140718, 9) . df.tail(3) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 140715 2021-06-01 | NaN | Timor-Leste | -8.8742 | 125.7275 | 0 | 4515 | 0 | -4515 | . 140716 2021-06-02 | NaN | Timor-Leste | -8.8742 | 125.7275 | 0 | 4692 | 0 | -4692 | . 140717 2021-06-03 | NaN | Timor-Leste | -8.8742 | 125.7275 | 0 | 4826 | 0 | -4826 | . df.loc[0] . Date 2020-01-22 00:00:00 Province/State NaN Country Afghanistan Lat 33.9391 Long 67.71 Confirmed 0 Recovered 0 Deaths 0 Active 0 Name: 0, dtype: object . Data Wrangling . df[&#39;Province/State&#39;] = df[&#39;Province/State&#39;].fillna(&quot;&quot;) df . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 0 2020-01-22 | | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 1 2020-01-23 | | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 2 2020-01-24 | | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 3 2020-01-25 | | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . 4 2020-01-26 | | Afghanistan | 33.93911 | 67.709953 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 140713 2021-05-30 | | Timor-Leste | -8.87420 | 125.727500 | 0 | 4233 | 0 | -4233 | . 140714 2021-05-31 | | Timor-Leste | -8.87420 | 125.727500 | 0 | 4352 | 0 | -4352 | . 140715 2021-06-01 | | Timor-Leste | -8.87420 | 125.727500 | 0 | 4515 | 0 | -4515 | . 140716 2021-06-02 | | Timor-Leste | -8.87420 | 125.727500 | 0 | 4692 | 0 | -4692 | . 140717 2021-06-03 | | Timor-Leste | -8.87420 | 125.727500 | 0 | 4826 | 0 | -4826 | . 140718 rows × 9 columns . country_daywise.head(5) . Date Country Confirmed Deaths Recovered Active New Cases New Recovered New Deaths . 0 2020-01-23 | Afghanistan | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 2020-01-24 | Afghanistan | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01-25 | Afghanistan | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01-26 | Afghanistan | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01-27 | Afghanistan | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . countrywise.head(5) . Country Confirmed Deaths Recovered Active New Cases Deaths / 100 Cases Recovered / 100 Cases Deaths / 100 Recovered Population Cases / Million People Confirmed last week 1 week change 1 week % increase . 0 Afghanistan | 72977 | 2973 | 57741 | 12263 | 1139 | 4.07 | 79.12 | 5.15 | 38928341 | 1875.0 | 66903 | 6074 | 9.08 | . 1 Albania | 132337 | 2451 | 129473 | 413 | 22 | 1.85 | 97.84 | 1.89 | 2877800 | 45985.0 | 132229 | 108 | 0.08 | . 2 Algeria | 129218 | 3480 | 90057 | 35681 | 305 | 2.69 | 69.69 | 3.86 | 43851043 | 2947.0 | 127361 | 1857 | 1.46 | . 3 Andorra | 13729 | 127 | 13479 | 123 | 2 | 0.93 | 98.18 | 0.94 | 77265 | 177687.0 | 13664 | 65 | 0.48 | . 4 Angola | 34752 | 772 | 28190 | 5790 | 201 | 2.22 | 81.12 | 2.74 | 32866268 | 1057.0 | 32933 | 1819 | 5.52 | . daywise.head(5) . Date Confirmed Deaths Recovered Active New Cases Deaths / 100 Cases Recovered / 100 Cases Deaths / 100 Recovered No. of Countries . 0 2020-01-23 | 655 | 18 | 32 | 605 | 99 | 2.75 | 4.89 | 56.25 | 8 | . 1 2020-01-24 | 941 | 26 | 39 | 876 | 287 | 2.76 | 4.14 | 66.67 | 9 | . 2 2020-01-25 | 1433 | 42 | 42 | 1349 | 494 | 2.93 | 2.93 | 100.00 | 11 | . 3 2020-01-26 | 2118 | 56 | 56 | 2006 | 685 | 2.64 | 2.64 | 100.00 | 13 | . 4 2020-01-27 | 2927 | 82 | 65 | 2780 | 809 | 2.80 | 2.22 | 126.15 | 16 | . df.isna().sum() . Date 0 Province/State 0 Country 0 Lat 0 Long 0 Confirmed 0 Recovered 0 Deaths 0 Active 0 dtype: int64 . df = df.dropna() sns.heatmap(df.isna()) plt.show() . confirmed = df.groupby(&#39;Date&#39;).sum()[&#39;Confirmed&#39;].reset_index() confirmed . Date Confirmed . 0 2020-01-22 | 557 | . 1 2020-01-23 | 655 | . 2 2020-01-24 | 941 | . 3 2020-01-25 | 1433 | . 4 2020-01-26 | 2118 | . ... ... | ... | . 494 2021-05-30 | 170345677 | . 495 2021-05-31 | 170724212 | . 496 2021-06-01 | 171187600 | . 497 2021-06-02 | 171680812 | . 498 2021-06-03 | 172169929 | . 499 rows × 2 columns . recovered = df.groupby(&#39;Date&#39;).sum()[&#39;Recovered&#39;].reset_index() recovered . Date Recovered . 0 2020-01-22 | 30 | . 1 2020-01-23 | 32 | . 2 2020-01-24 | 39 | . 3 2020-01-25 | 42 | . 4 2020-01-26 | 56 | . ... ... | ... | . 494 2021-05-30 | 107630598 | . 495 2021-05-31 | 108159767 | . 496 2021-06-01 | 108743650 | . 497 2021-06-02 | 109271887 | . 498 2021-06-03 | 109700897 | . 499 rows × 2 columns . deaths = df.groupby(&#39;Date&#39;).sum()[&#39;Deaths&#39;].reset_index() deaths . Date Deaths . 0 2020-01-22 | 17 | . 1 2020-01-23 | 18 | . 2 2020-01-24 | 26 | . 3 2020-01-25 | 42 | . 4 2020-01-26 | 56 | . ... ... | ... | . 494 2021-05-30 | 3541337 | . 495 2021-05-31 | 3550017 | . 496 2021-06-01 | 3565115 | . 497 2021-06-02 | 3691664 | . 498 2021-06-03 | 3701573 | . 499 rows × 2 columns . df.isnull().sum() . Date 0 Province/State 0 Country 0 Lat 0 Long 0 Confirmed 0 Recovered 0 Deaths 0 Active 0 dtype: int64 . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 140718 entries, 0 to 140717 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 Date 140718 non-null datetime64[ns] 1 Province/State 140718 non-null object 2 Country 140718 non-null object 3 Lat 140718 non-null float64 4 Long 140718 non-null float64 5 Confirmed 140718 non-null int64 6 Recovered 140718 non-null int64 7 Deaths 140718 non-null int64 8 Active 140718 non-null int64 dtypes: datetime64[ns](1), float64(2), int64(4), object(2) memory usage: 10.7+ MB . df.query(&#39;Country == &quot;US&quot;&#39;) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 125249 2020-01-22 | | US | 40.0 | -100.0 | 1 | 0 | 0 | 1 | . 125250 2020-01-23 | | US | 40.0 | -100.0 | 1 | 0 | 0 | 1 | . 125251 2020-01-24 | | US | 40.0 | -100.0 | 2 | 0 | 0 | 2 | . 125252 2020-01-25 | | US | 40.0 | -100.0 | 2 | 0 | 0 | 2 | . 125253 2020-01-26 | | US | 40.0 | -100.0 | 5 | 0 | 0 | 5 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 125743 2021-05-30 | | US | 40.0 | -100.0 | 33261731 | 0 | 594443 | 32667288 | . 125744 2021-05-31 | | US | 40.0 | -100.0 | 33267507 | 0 | 594585 | 32672922 | . 125745 2021-06-01 | | US | 40.0 | -100.0 | 33290450 | 0 | 595223 | 32695227 | . 125746 2021-06-02 | | US | 40.0 | -100.0 | 33307363 | 0 | 595833 | 32711530 | . 125747 2021-06-03 | | US | 40.0 | -100.0 | 33326437 | 0 | 596434 | 32730003 | . 499 rows × 9 columns . confirmed.tail() . Date Confirmed . 494 2021-05-30 | 170345677 | . 495 2021-05-31 | 170724212 | . 496 2021-06-01 | 171187600 | . 497 2021-06-02 | 171680812 | . 498 2021-06-03 | 172169929 | . recovered.tail() . Date Recovered . 494 2021-05-30 | 107630598 | . 495 2021-05-31 | 108159767 | . 496 2021-06-01 | 108743650 | . 497 2021-06-02 | 109271887 | . 498 2021-06-03 | 109700897 | . deaths.tail() . Date Deaths . 494 2021-05-30 | 3541337 | . 495 2021-05-31 | 3550017 | . 496 2021-06-01 | 3565115 | . 497 2021-06-02 | 3691664 | . 498 2021-06-03 | 3701573 | . Data Analysis &amp; Visualization . df_confirmed = df.sort_values(by =&#39;Confirmed&#39;, ascending=False) df_confirmed.head(3) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 125747 2021-06-03 | | US | 40.0 | -100.0 | 33326437 | 0 | 596434 | 32730003 | . 125746 2021-06-02 | | US | 40.0 | -100.0 | 33307363 | 0 | 595833 | 32711530 | . 125745 2021-06-01 | | US | 40.0 | -100.0 | 33290450 | 0 | 595223 | 32695227 | . df_recovered = df.sort_values(by =&#39;Recovered&#39;, ascending=False) df_recovered.head(3) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 73851 2021-06-03 | | India | 20.593684 | 78.96288 | 28574350 | 26597655 | 340702 | 1635993 | . 73850 2021-06-02 | | India | 20.593684 | 78.96288 | 28441986 | 26390584 | 337989 | 1713413 | . 73849 2021-06-01 | | India | 20.593684 | 78.96288 | 28307832 | 26179085 | 335102 | 1793645 | . df_deaths = df.sort_values(by =&#39;Deaths&#39;, ascending=False) df_deaths.head(3) . Date Province/State Country Lat Long Confirmed Recovered Deaths Active . 125747 2021-06-03 | | US | 40.0 | -100.0 | 33326437 | 0 | 596434 | 32730003 | . 125746 2021-06-02 | | US | 40.0 | -100.0 | 33307363 | 0 | 595833 | 32711530 | . 125745 2021-06-01 | | US | 40.0 | -100.0 | 33290450 | 0 | 595223 | 32695227 | . fig = go.Figure() fig.add_trace(go.Scatter(x = confirmed[&#39;Date&#39;], y = confirmed[&#39;Confirmed&#39;])) fig.show(renderer=&quot;colab&quot;) . . . fig = go.Figure() fig.add_trace(go.Scatter(x = confirmed[&#39;Date&#39;], y = confirmed[&#39;Confirmed&#39;], mode = &#39;lines&#39;, name= &#39;Confirmed&#39;, line = dict(color = &quot;Blue&quot;))) fig.add_trace(go.Scatter(x = recovered[&#39;Date&#39;], y = recovered[&#39;Recovered&#39;], mode = &#39;lines&#39;, name= &#39;Recovered&#39;, line = dict(color = &quot;Green&quot;))) fig.add_trace(go.Scatter(x = deaths[&#39;Date&#39;], y = deaths[&#39;Deaths&#39;], mode = &#39;lines&#39;, name= &#39;Deaths&#39;, line = dict(color = &quot;Red&quot;))) fig.update_layout(title = &#39;Worldwide Covid_19 Cases&#39;, xaxis_tickfont_size = 12, yaxis = dict(title = &#39;Number of Cases&#39;)) fig.show(renderer=&quot;colab&quot;) . . . df[&#39;Date&#39;] = df[&#39;Date&#39;].astype(str) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 140718 entries, 0 to 140717 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 Date 140718 non-null object 1 Province/State 140718 non-null object 2 Country 140718 non-null object 3 Lat 140718 non-null float64 4 Long 140718 non-null float64 5 Confirmed 140718 non-null int64 6 Recovered 140718 non-null int64 7 Deaths 140718 non-null int64 8 Active 140718 non-null int64 dtypes: float64(2), int64(4), object(3) memory usage: 10.7+ MB . fig = px.density_mapbox(df, lat = &#39;Lat&#39;, lon = &#39;Long&#39;, hover_name = &#39;Country&#39;, hover_data = [&#39;Confirmed&#39;, &#39;Recovered&#39;, &#39;Deaths&#39;], animation_frame=&#39;Date&#39;, color_continuous_scale=&#39;Portland&#39;, radius = 6, zoom = 0, height = 600 ) fig.update_layout(title = &#39;Worldwide Covid_19 Cases with Time Lapse&#39;) fig.update_layout(mapbox_style = &#39;open-street-map&#39;, mapbox_center_lon = 0) fig.show(renderer=&quot;colab&quot;) . Output hidden; open in https://colab.research.google.com to view. . df[&#39;Date&#39;] = pd.to_datetime(df[&#39;Date&#39;]) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 140718 entries, 0 to 140717 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 Date 140718 non-null datetime64[ns] 1 Province/State 140718 non-null object 2 Country 140718 non-null object 3 Lat 140718 non-null float64 4 Long 140718 non-null float64 5 Confirmed 140718 non-null int64 6 Recovered 140718 non-null int64 7 Deaths 140718 non-null int64 8 Active 140718 non-null int64 dtypes: datetime64[ns](1), float64(2), int64(4), object(2) memory usage: 10.7+ MB . def plotCorrelationMatrix(df, graphWidth): filename = df df = df.dropna(&#39;columns&#39;) # drop columns with NaN df = df[[col for col in df if df[col].nunique() &gt; 1]] # keep columns where there are more than 1 unique values if df.shape[1] &lt; 2: print(f&#39;No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2&#39;) return corr = df.corr() plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor=&#39;w&#39;, edgecolor=&#39;k&#39;) corrMat = plt.matshow(corr, fignum = 1) plt.xticks(range(len(corr.columns)), corr.columns, rotation=90) plt.yticks(range(len(corr.columns)), corr.columns) plt.gca().xaxis.tick_bottom() plt.colorbar(corrMat) plt.title(f&#39;Correlation Matrix for {filename}&#39;, fontsize=15) plt.show() . plotCorrelationMatrix(df, 8) . Cases Over the time with Area Plot . temp = df.groupby(&#39;Date&#39;)[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].sum().reset_index() temp = temp[temp[&#39;Date&#39;] == max(temp[&#39;Date&#39;])].reset_index(drop = True) temp . Date Confirmed Deaths Recovered Active . 0 2021-06-03 | 172169929 | 3701573 | 109700897 | 58767459 | . !pip install --upgrade plotly . Collecting plotly Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB) |████████████████████████████████| 13.2MB 328kB/s Requirement already satisfied, skipping upgrade: retrying&gt;=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3) Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0) Installing collected packages: plotly Found existing installation: plotly 4.4.1 Uninstalling plotly-4.4.1: Successfully uninstalled plotly-4.4.1 Successfully installed plotly-4.14.3 . tm = temp.melt(id_vars = &#39;Date&#39;, value_vars = [&#39;Active&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;]) fig = px.treemap(tm, path=[&#39;variable&#39;], values = &#39;value&#39;, height = 250, width = 700, color_discrete_sequence=[act, rec, dth ]) fig.data[0].textinfo = &#39;label+text+value&#39; fig.show() . TypeError Traceback (most recent call last) &lt;ipython-input-42-8ff7f614d1b6&gt; in &lt;module&gt;() 1 # Plot the uptodate 2 tm = temp.melt(id_vars = &#39;Date&#39;, value_vars = [&#39;Active&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;]) -&gt; 3 fig = px.treemap(tm, path=[&#39;variable&#39;], values = &#39;value&#39;, height = 250, width = 700, color_discrete_sequence=[act, rec, dth ]) 4 5 fig.data[0].textinfo = &#39;label+text+value&#39; TypeError: treemap() got an unexpected keyword argument &#39;path&#39; . temp = df.groupby(&#39;Date&#39;)[&#39;Recovered&#39;, &#39;Deaths&#39;, &#39;Active&#39;].sum().reset_index() . temp = df.groupby(&#39;Date&#39;)[&#39;Recovered&#39;, &#39;Deaths&#39;, &#39;Active&#39;].sum().reset_index() temp = temp.melt(id_vars = &#39;Date&#39;, value_vars = [&#39;Recovered&#39;, &#39;Deaths&#39;, &#39;Active&#39;], var_name=&#39;Çase&#39;, value_name= &#39;Count&#39;) temp . temp = df.groupby(&#39;Date&#39;)[&#39;Recovered&#39;, &#39;Deaths&#39;, &#39;Active&#39;].sum().reset_index() temp = temp.melt(id_vars = &#39;Date&#39;, value_vars = [&#39;Recovered&#39;, &#39;Deaths&#39;, &#39;Active&#39;], var_name=&#39;Çase&#39;, value_name= &#39;Count&#39;) fig = px.area(temp, x = &#39;Date&#39;, y= &#39;Count&#39;, color = &#39;Çase&#39;, height = 500, title = &#39;Cases over time&#39;, color_discrete_sequence=[rec, dth, act]) fig.update_layout(xaxis_rangeslider_visible=True) fig.show() . Worldwide scenario . temp = df[df[&#39;Date&#39;] == max(df[&#39;Date&#39;])] m = folium.Map(location=[0, 0], tiles=&#39;cartodbpositron&#39;, min_zoom = 1, max_zoom = 4, zoom_start=1 ) for i in range(0, len(temp)): folium.Circle(location=[temp.iloc[i][&#39;Lat&#39;], temp.iloc[i][&#39;Long&#39;]], color = &#39;crimson&#39;, fill = &#39;crimson&#39;, tooltip = &#39;&lt;li&gt;&lt;bold&gt; Country: &#39; + str(temp.iloc[i][&#39;Country&#39;]) + &#39;&lt;li&gt;&lt;bold&gt; Provinvce: &#39; + str(temp.iloc[i][&#39;Province/State&#39;]) + &#39;&lt;li&gt;&lt;bold&gt; Confirmed: &#39; + str(temp.iloc[i][&#39;Confirmed&#39;]) + &#39;&lt;li&gt;&lt;bold&gt; Deaths: &#39; + str(temp.iloc[i][&#39;Deaths&#39;]), radius = int(temp.iloc[i][&#39;Confirmed&#39;]) **0.5).add_to(m) m . country_daywise.head() . fig = px.choropleth(country_daywise, locations= &#39;Country&#39;, locationmode= &#39;country names&#39;, color = np.log(country_daywise[&#39;Confirmed&#39;]), hover_name = &#39;Country&#39;, animation_frame=country_daywise[&#39;Date&#39;].dt.strftime(&#39;%y-%m-%d&#39;), title = &#39;Cases over time&#39;, color_continuous_scale=px.colors.sequential.Inferno) fig.update(layout_coloraxis_showscale = True) fig.show() . fig_c = px.choropleth(countrywise, locations=&#39;Country&#39;, locationmode =&#39;country names&#39;, color = np.log(countrywise[&#39;Confirmed&#39;]), hover_name =&#39;Country&#39;, hover_data = [&#39;Confirmed&#39;]) temp = countrywise[countrywise[&#39;Deaths&#39;]&gt;0] fig_d = px.choropleth(temp, locations=&#39;Country&#39;, locationmode =&#39;country names&#39;, color = np.log(temp[&#39;Deaths&#39;]), hover_name =&#39;Country&#39;, hover_data = [&#39;Deaths&#39;]) fig = make_subplots(rows = 1, cols = 2, subplot_titles=[&#39;Confirmed&#39;, &#39;Deaths&#39;], specs = [[{&#39;type&#39;: &#39;choropleth&#39;}, {&#39;type&#39;: &#39;choropleth&#39;}]]) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col = 1) fig.add_trace(fig_d[&#39;data&#39;][0], row = 1, col = 2) fig.update(layout_coloraxis_showscale = False) fig.show() . Recovery and deaths per 100 cases . fig_c = px.bar(daywise, x = &#39;Date&#39;, y = &#39;Confirmed&#39;, color_discrete_sequence=[act]) fig_c = px.bar(daywise, x = &#39;Date&#39;, y = &#39;Deaths&#39;, color_discrete_sequence=[dth]) fig = make_subplots(rows = 1, cols = 2, shared_xaxes=False, horizontal_spacing=0.1, subplot_titles=(&#39;Confirmed Cases&#39;, &#39;Death Cases&#39;)) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col = 1) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col = 2) fig.update_layout(height = 400) fig.show() . daywise.columns . fig1 = px.line(daywise, x = &#39;Date&#39;, y = &#39;Deaths / 100 Cases&#39;, color_discrete_sequence=[dth]) fig2 = px.line(daywise, x = &#39;Date&#39;, y = &#39;Recovered / 100 Cases&#39;, color_discrete_sequence=[dth]) fig3 = px.line(daywise, x = &#39;Date&#39;, y = &#39;Deaths / 100 Recovered&#39;, color_discrete_sequence=[dth]) fig = make_subplots(rows = 1, cols = 3, shared_xaxes=False, subplot_titles=(&#39;Deaths /100 Cases&#39;, &#39;Recovered / 100 cases&#39;, &#39;Deaths / 100 Recovered&#39;)) fig.add_trace(fig1[&#39;data&#39;][0], row = 1, col = 1) fig.add_trace(fig1[&#39;data&#39;][0], row = 1, col = 2) fig.add_trace(fig1[&#39;data&#39;][0], row = 1, col = 3) fig.update_layout(height = 400) fig.show() . Countrywise new cases . fig_c = px.bar(daywise, x = &#39;Date&#39;, y= &#39;Confirmed&#39;, color_discrete_sequence=[act]) fig_d = px.bar(daywise, x = &#39;Date&#39;, y= &#39;No. of Countries&#39;, color_discrete_sequence=[dth]) fig = make_subplots(rows = 1, cols = 2, shared_xaxes=False, horizontal_spacing=0.1, subplot_titles=(&#39;Number of new cases per Day&#39;, &#39;No of Countries&#39;)) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col=1) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col=2) fig.show() . Top 15 Countries Case Analysis . top = 15 fig_c = px.bar(countrywise.sort_values(&#39;Confirmed&#39;).tail(top), x = &#39;Confirmed&#39;, y = &#39;Country&#39;, text = &#39;Confirmed&#39;, orientation =&#39;h&#39;, color_discrete_sequence=[act]) fig_d = px.bar(countrywise.sort_values(&#39;Deaths&#39;).tail(top), x = &#39;Deaths&#39;, y = &#39;Country&#39;, text = &#39;Deaths&#39;, orientation =&#39;h&#39;, color_discrete_sequence=[dth]) fig_a = px.bar(countrywise.sort_values(&#39;Active&#39;).tail(top), x = &#39;Active&#39;, y = &#39;Country&#39;, text = &#39;Active&#39;, orientation =&#39;h&#39;, color_discrete_sequence=[&#39;#434343&#39;]) fig_r = px.bar(countrywise.sort_values(&#39;Recovered&#39;).tail(top), x = &#39;Recovered&#39;, y = &#39;Country&#39;, text = &#39;Recovered&#39;, orientation =&#39;h&#39;, color_discrete_sequence=[rec]) fig = make_subplots(rows= 2, cols = 2, shared_xaxes=False, horizontal_spacing=0.14, vertical_spacing=.1, subplot_titles=(&#39;Confirmed Cases&#39;, &#39;Deaths Reported&#39;, &#39;Recovered Cases&#39;, &#39;Active Cases&#39;)) fig.add_trace(fig_c[&#39;data&#39;][0], row = 1, col =1) fig.add_trace(fig_d[&#39;data&#39;][0], row = 1, col =2) fig.add_trace(fig_r[&#39;data&#39;][0], row = 2, col =1) fig.add_trace(fig_a[&#39;data&#39;][0], row = 2, col =2) fig.update_layout(height = 1000) fig.show() . Line Plot on Countrywise scenario . fig = px.line(country_daywise, x = &#39;Date&#39;, y = &#39;Confirmed&#39;, color = &#39;Country&#39;, height = 600, title = &#39;Çonfirmed&#39;, color_discrete_sequence = px.colors.cyclical.mygbm) fig.show() . fig = px.line(country_daywise, x = &#39;Date&#39;, y = &#39;Deaths&#39;, color = &#39;Country&#39;, height = 600, title = &#39;Deaths&#39;, color_discrete_sequence = px.colors.cyclical.mygbm) fig.show() . fig = px.line(country_daywise, x = &#39;Date&#39;, y = &#39;Recovered&#39;, color = &#39;Country&#39;, height = 600, title = &#39;Çonfirmed&#39;, color_discrete_sequence = px.colors.cyclical.mygbm) fig.show() . Tree Map Analysis . Confirmed Cases . full_latest = df[df[&#39;Date&#39;] == max(df[&#39;Date&#39;])] fig = px.treemap(full_latest.sort_values(by = &#39;Confirmed&#39;, ascending = False).reset_index(drop = True), path = [&#39;Country&#39;, &#39;Province/State&#39;], values = &#39;Confirmed&#39;, height = 700, title = &#39;Number of Confirmed cases&#39;, color_discrete_sequence = px.colors.qualitative.Dark2) fig.data[0].textinfo = &#39;label+text+value&#39; fig.show() . Mortality . full_latest = df[df[&#39;Date&#39;] == max(df[&#39;Date&#39;])] fig = px.treemap(full_latest.sort_values(by = &#39;Deaths&#39;, ascending = False).reset_index(drop = True), path = [&#39;Country&#39;, &#39;Province/State&#39;], values = &#39;Deaths&#39;, height = 700, title = &#39;Number of Deaths&#39;, color_discrete_sequence = px.colors.qualitative.Dark2) fig.data[0].textinfo = &#39;label+text+value&#39; fig.show() . Confirmed Cases Country and Day wise . country_daywise.head() . Covid19 and other Epidemics . epidemics = pd.DataFrame({ &#39;epidemic&#39; : [&#39;COVID-19&#39;, &#39;SARS&#39;, &#39;EBOLA&#39;, &#39;MERS&#39;, &#39;H1N1&#39;], &#39;start_year&#39; : [2019, 2003, 2014, 2012, 2009], &#39;end_year&#39; : [2020, 2004, 2016, 2017, 2010], &#39;confirmed&#39; : [full_latest[&#39;Confirmed&#39;].sum(), 8096, 28646, 2494, 6724149], &#39;deaths&#39; : [full_latest[&#39;Deaths&#39;].sum(), 774, 11323, 858, 19654] }) epidemics[&#39;mortality&#39;] = round((epidemics[&#39;deaths&#39;]/epidemics[&#39;confirmed&#39;])*100, 2) # epidemics.head() . temp = epidemics.melt(id_vars=&#39;epidemic&#39;, value_vars=[&#39;confirmed&#39;, &#39;deaths&#39;, &#39;mortality&#39;], var_name=&#39;Case&#39;, value_name=&#39;Value&#39;) fig = px.bar(temp, x=&quot;epidemic&quot;, y=&quot;Value&quot;, color=&#39;epidemic&#39;, text=&#39;Value&#39;, facet_col=&quot;Case&quot;, color_discrete_sequence = px.colors.qualitative.Bold) fig.update_traces(textposition=&#39;outside&#39;) fig.update_layout(uniformtext_minsize=8, uniformtext_mode=&#39;hide&#39;) fig.update_yaxes(showticklabels=False) fig.layout.yaxis2.update(matches=None) fig.layout.yaxis3.update(matches=None) fig.update_layout(width=1000) fig.show() . Acknowledgements: https://github.com/laxmimerit/Covid-19-Preprocessed-Dataset.git . KGP Talkie .",
            "url": "https://sri-spec.github.io/Blog/2021/10/05/Covid_19_CodeinPlace_Project-(1).html",
            "relUrl": "/2021/10/05/Covid_19_CodeinPlace_Project-(1).html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sri-spec.github.io/Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Summary statistics",
            "content": "Palmer Archipelago (Antarctica) penguin data. . Data Source: Dr. Kirtsten Gorman and Palmer Station, Antartica, LTER. . Problem Statement: We compare different physical aspects of Penguins like, body mass, flipper length, culmen length, culmen depth to predict the species of the Penguin. . . import numpy as np import pandas as pd from sklearn import tree import graphviz . from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor import seaborn as sns . from google.colab import files uploaded = files.upload() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving penguins.csv to penguins.csv . df = pd.read_csv(&quot;penguins.csv&quot;) . df . species island Region culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g sex Delta 15 N (o/oo) Delta 13 C (o/oo) Clutch Completion Date Egg . 0 Adelie | Torgersen | Anvers | 39.1 | 18.7 | 181.0 | 3750.0 | MALE | NaN | NaN | Yes | 11/11/2007 | . 1 Adelie | Torgersen | Anvers | 39.5 | 17.4 | 186.0 | 3800.0 | FEMALE | 8.94956 | -24.69454 | Yes | 11/11/2007 | . 2 Adelie | Torgersen | Anvers | 40.3 | 18.0 | 195.0 | 3250.0 | FEMALE | 8.36821 | -25.33302 | Yes | 11/16/2007 | . 3 Adelie | Torgersen | Anvers | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Yes | 11/16/2007 | . 4 Adelie | Torgersen | Anvers | 36.7 | 19.3 | 193.0 | 3450.0 | FEMALE | 8.76651 | -25.32426 | Yes | 11/16/2007 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 339 Gentoo | Biscoe | Anvers | NaN | NaN | NaN | NaN | NaN | NaN | NaN | No | 12/1/2009 | . 340 Gentoo | Biscoe | Anvers | 46.8 | 14.3 | 215.0 | 4850.0 | FEMALE | 8.41151 | -26.13832 | Yes | 11/22/2009 | . 341 Gentoo | Biscoe | Anvers | 50.4 | 15.7 | 222.0 | 5750.0 | MALE | 8.30166 | -26.04117 | Yes | 11/22/2009 | . 342 Gentoo | Biscoe | Anvers | 45.2 | 14.8 | 212.0 | 5200.0 | FEMALE | 8.24246 | -26.11969 | Yes | 11/22/2009 | . 343 Gentoo | Biscoe | Anvers | 49.9 | 16.1 | 213.0 | 5400.0 | MALE | 8.36390 | -26.15531 | Yes | 11/22/2009 | . 344 rows × 12 columns . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 344 entries, 0 to 343 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 species 344 non-null object 1 island 344 non-null object 2 Region 344 non-null object 3 culmen_length_mm 342 non-null float64 4 culmen_depth_mm 342 non-null float64 5 flipper_length_mm 342 non-null float64 6 body_mass_g 342 non-null float64 7 sex 334 non-null object 8 Delta 15 N (o/oo) 330 non-null float64 9 Delta 13 C (o/oo) 331 non-null float64 10 Clutch Completion 344 non-null object 11 Date Egg 344 non-null object dtypes: float64(6), object(6) memory usage: 32.4+ KB . df.shape . (344, 12) . df.dtypes . species object island object Region object culmen_length_mm float64 culmen_depth_mm float64 flipper_length_mm float64 body_mass_g float64 sex object Delta 15 N (o/oo) float64 Delta 13 C (o/oo) float64 Clutch Completion object Date Egg object dtype: object . missing_values = [&quot;NA&quot;, &quot;NAN&quot;, &quot;n/a&quot;, &quot;na&quot;, &quot;Empty&quot;, &quot;--&quot;] . df = pd.read_csv(&quot;penguins.csv&quot;, na_values = missing_values) . df.isnull().any() # shows which column missing values are exactly found. There are 7 columns with null values . species False island False Region False culmen_length_mm True culmen_depth_mm True flipper_length_mm True body_mass_g True sex True Delta 15 N (o/oo) True Delta 13 C (o/oo) True Clutch Completion False Date Egg False dtype: bool . df.fillna(df.mean(), inplace=True) . df.isnull().any() . species False island False Region False culmen_length_mm False culmen_depth_mm False flipper_length_mm False body_mass_g False sex True Delta 15 N (o/oo) False Delta 13 C (o/oo) False Clutch Completion False Date Egg False dtype: bool . def binarize_sex(val): if val == &#39;Male&#39;: return 1 else: return 0 . df[&#39;sex&#39;] = df[&#39;sex&#39;].apply(binarize_sex) . df.dropna(inplace=True) . df.isnull().any() . species False island False Region False culmen_length_mm False culmen_depth_mm False flipper_length_mm False body_mass_g False sex False Delta 15 N (o/oo) False Delta 13 C (o/oo) False Clutch Completion False Date Egg False dtype: bool . df.isna().sum() . species 0 island 0 Region 0 culmen_length_mm 0 culmen_depth_mm 0 flipper_length_mm 0 body_mass_g 0 sex 0 Delta 15 N (o/oo) 0 Delta 13 C (o/oo) 0 Clutch Completion 0 Date Egg 0 dtype: int64 . import matplotlib.pyplot as plt import seaborn as sns df=df.dropna() sns.heatmap(df.isna()) plt.show() . df.describe() . culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g sex Delta 15 N (o/oo) Delta 13 C (o/oo) . count 344.000000 | 344.000000 | 344.000000 | 344.000000 | 344.0 | 344.000000 | 344.000000 | . mean 43.921930 | 17.151170 | 200.915205 | 4201.754386 | 0.0 | 8.733382 | -25.686292 | . std 5.443643 | 1.969027 | 14.020657 | 799.613058 | 0.0 | 0.540392 | 0.778770 | . min 32.100000 | 13.100000 | 172.000000 | 2700.000000 | 0.0 | 7.632200 | -27.018540 | . 25% 39.275000 | 15.600000 | 190.000000 | 3550.000000 | 0.0 | 8.307415 | -26.285460 | . 50% 44.250000 | 17.300000 | 197.000000 | 4050.000000 | 0.0 | 8.687455 | -25.793660 | . 75% 48.500000 | 18.700000 | 213.000000 | 4750.000000 | 0.0 | 9.136170 | -25.089467 | . max 59.600000 | 21.500000 | 231.000000 | 6300.000000 | 0.0 | 10.025440 | -23.787670 | . Describe the column names: . df.columns # Delta 15 N is a number denoting the measure of the ratio of stable isotopes 15N . Index([&#39;species&#39;, &#39;island&#39;, &#39;Region&#39;, &#39;culmen_length_mm&#39;, &#39;culmen_depth_mm&#39;, &#39;flipper_length_mm&#39;, &#39;body_mass_g&#39;, &#39;sex&#39;, &#39;Delta 15 N (o/oo)&#39;, &#39;Delta 13 C (o/oo)&#39;, &#39;Clutch Completion&#39;, &#39;Date Egg&#39;], dtype=&#39;object&#39;) . df[&#39;culmen_depth_mm&#39;].mean() . 17.151169590643274 . df[&#39;culmen_depth_mm&#39;].mean() . 17.151169590643274 . df[&#39;culmen_length_mm&#39;].mean() . 43.92192982456141 . df[&#39;body_mass_g&#39;].median() . 4050.0 . df[&#39;species&#39;].count() . 344 . df.head() . species island Region culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g sex Delta 15 N (o/oo) Delta 13 C (o/oo) Clutch Completion Date Egg . 0 Adelie | Torgersen | Anvers | 39.10000 | 18.70000 | 181.000000 | 3750.000000 | 0 | 8.733382 | -25.686292 | Yes | 11/11/2007 | . 1 Adelie | Torgersen | Anvers | 39.50000 | 17.40000 | 186.000000 | 3800.000000 | 0 | 8.949560 | -24.694540 | Yes | 11/11/2007 | . 2 Adelie | Torgersen | Anvers | 40.30000 | 18.00000 | 195.000000 | 3250.000000 | 0 | 8.368210 | -25.333020 | Yes | 11/16/2007 | . 3 Adelie | Torgersen | Anvers | 43.92193 | 17.15117 | 200.915205 | 4201.754386 | 0 | 8.733382 | -25.686292 | Yes | 11/16/2007 | . 4 Adelie | Torgersen | Anvers | 36.70000 | 19.30000 | 193.000000 | 3450.000000 | 0 | 8.766510 | -25.324260 | Yes | 11/16/2007 | . Data Visualization . Penguins &amp; their distribtution in Antartica . import matplotlib.pyplot as plt . plt.pie(df[&quot;species&quot;].value_counts(),labels = df[&quot;species&quot;].unique()) plt.show() . p = sns.load_dataset(&#39;penguins&#39;) . c = p.groupby(&#39;species&#39;)[&#39;species&#39;].count() . c . species Adelie 152 Chinstrap 68 Gentoo 124 Name: species, dtype: int64 . sns.countplot(&#39;species&#39;,data=p, palette=(&#39;DarkOrange&#39;, &#39;MediumOrchid&#39;, &#39;Teal&#39;)) plt.show() . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . sns.countplot(x = &quot;island&quot;, data = p) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff40e6a4250&gt; . sns.barplot(x = &quot;island&quot;, y = &quot;body_mass_g&quot;, data = p) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff418c57a90&gt; . sns.pairplot(data = p, hue=&#39;species&#39;, palette=None) . &lt;seaborn.axisgrid.PairGrid at 0x7ff40e6b7dd0&gt; . sns.scatterplot(x = p.bill_length_mm, y = p.bill_depth_mm, hue = p.species, palette=None) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff40dfcf390&gt; . sns.scatterplot(x = p.body_mass_g, y = p.flipper_length_mm, hue = p.species, palette=None) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff40dfada50&gt; . sns.heatmap(df.corr()) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff40c6c4e10&gt; . Data Partition . X_train.dtypes . species object island object Region object culmen_length_mm float64 sex int64 Delta 15 N (o/oo) float64 Delta 13 C (o/oo) float64 Clutch Completion object Date Egg object dtype: object . from sklearn.datasets import make_blobs from sklearn.model_selection import train_test_split # create dataset X, y = make_blobs(n_samples=1000) # split into train test sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33) print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) . (670, 2) (330, 2) (670,) (330,) . parameters = [&#39;culmen_length_mm&#39;, &#39;culmen_depth_mm&#39;, &#39;flipper_length_mm&#39;, &#39;body_mass_g&#39;, &#39;sex&#39;, &#39;Delta 15 N (o/oo)&#39;, &#39;Delta 13 C (o/oo)&#39;] result = &quot;species&quot; . model = DecisionTreeClassifier(max_depth=5) model.fit(df[parameters], df[result]) . DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion=&#39;gini&#39;, max_depth=5, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=&#39;deprecated&#39;, random_state=None, splitter=&#39;best&#39;) . model.score(df[parameters], df[result]) . 0.997093023255814 . dot_data = tree.export_graphviz(model, feature_names=parameters, filled=True, rounded=True) graph = graphviz.Source(dot_data) graph . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Tree 0 flipper_length_mm &lt;= 206.5 gini = 0.636 samples = 344 value = [152, 68, 124] 1 culmen_length_mm &lt;= 44.65 gini = 0.427 samples = 215 value = [150, 63, 2] 0&#45;&gt;1 True 18 culmen_depth_mm &lt;= 17.65 gini = 0.104 samples = 129 value = [2, 5, 122] 0&#45;&gt;18 False 2 Delta 13 C (o/oo) &lt;= &#45;25.015 gini = 0.087 samples = 154 value = [147, 6, 1] 1&#45;&gt;2 11 Delta 13 C (o/oo) &lt;= &#45;25.643 gini = 0.124 samples = 61 value = [3, 57, 1] 1&#45;&gt;11 3 culmen_length_mm &lt;= 43.561 gini = 0.014 samples = 140 value = [139, 0, 1] 2&#45;&gt;3 6 culmen_length_mm &lt;= 40.25 gini = 0.49 samples = 14 value = [8, 6, 0] 2&#45;&gt;6 4 gini = 0.0 samples = 138 value = [138, 0, 0] 3&#45;&gt;4 5 gini = 0.5 samples = 2 value = [1, 0, 1] 3&#45;&gt;5 7 gini = 0.0 samples = 7 value = [7, 0, 0] 6&#45;&gt;7 8 body_mass_g &lt;= 4000.0 gini = 0.245 samples = 7 value = [1, 6, 0] 6&#45;&gt;8 9 gini = 0.0 samples = 6 value = [0, 6, 0] 8&#45;&gt;9 10 gini = 0.0 samples = 1 value = [1, 0, 0] 8&#45;&gt;10 12 culmen_length_mm &lt;= 47.1 gini = 0.444 samples = 3 value = [2, 0, 1] 11&#45;&gt;12 15 culmen_depth_mm &lt;= 21.15 gini = 0.034 samples = 58 value = [1, 57, 0] 11&#45;&gt;15 13 gini = 0.0 samples = 2 value = [2, 0, 0] 12&#45;&gt;13 14 gini = 0.0 samples = 1 value = [0, 0, 1] 12&#45;&gt;14 16 gini = 0.0 samples = 57 value = [0, 57, 0] 15&#45;&gt;16 17 gini = 0.0 samples = 1 value = [1, 0, 0] 15&#45;&gt;17 19 gini = 0.0 samples = 122 value = [0, 0, 122] 18&#45;&gt;19 20 culmen_length_mm &lt;= 46.55 gini = 0.408 samples = 7 value = [2, 5, 0] 18&#45;&gt;20 21 gini = 0.0 samples = 2 value = [2, 0, 0] 20&#45;&gt;21 22 gini = 0.0 samples = 5 value = [0, 5, 0] 20&#45;&gt;22 list(zip(parameters, model.feature_importances_)) . [(&#39;culmen_length_mm&#39;, 0.37287254604043296), (&#39;culmen_depth_mm&#39;, 0.05743618187396302), (&#39;flipper_length_mm&#39;, 0.5210554427945732), (&#39;body_mass_g&#39;, 0.007874616570268746), (&#39;sex&#39;, 0.0), (&#39;Delta 15 N (o/oo)&#39;, 0.0), (&#39;Delta 13 C (o/oo)&#39;, 0.04076121272076198)] . Questions for further analysis . Role the isotope Delta N plays in the Penguin Population size? . | Clutch completion does it always result in increase in population numbers? . |",
            "url": "https://sri-spec.github.io/Blog/2020/01/28/summary_statistics.html",
            "relUrl": "/2020/01/28/summary_statistics.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sri-spec.github.io/Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Srividhya Ammanur is a data science enthusiast. Data Science For All is a blog on “Doing Data Science”. [^1]. .",
          "url": "https://sri-spec.github.io/Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sri-spec.github.io/Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}